{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower-level Programming with PyTorch\n",
    "\n",
    "Let's dig just a little deeper. We'll first get the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from make_face_dataset import make_dataset\n",
    "\n",
    "\n",
    "act = ['Fran Drescher', 'America Ferrera', 'Kristin Chenoweth', 'Alec Baldwin', 'Bill Hader', 'Steve Carell']\n",
    "train_x, train_y = make_dataset(range(100), act)\n",
    "test_x, test_y = make_dataset(range(100,120),act)\n",
    "\n",
    "dim_x = 1024\n",
    "dim_h = 20\n",
    "dim_out = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,  let's define `Variable`s containing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_float = torch.FloatTensor\n",
    "\n",
    "x = Variable(torch.from_numpy(train_x), requires_grad=False).type(dtype_float)\n",
    "y = Variable(torch.from_numpy(train_y.astype(float)), requires_grad=False).type(dtype_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b0 = Variable(torch.randn((1, dim_h)), requires_grad=True)\n",
    "W0 = Variable(torch.randn((dim_x, dim_h)), requires_grad=True)\n",
    "\n",
    "b1 = Variable(torch.randn((1, dim_out)), requires_grad=True)\n",
    "W1 = Variable(torch.randn((dim_h, dim_out)), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that everything is accessible right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       "-1.1344  0.0258 -2.4930  0.3897  0.4594  0.1391 -0.5726  0.7777 -0.2557 -2.1650\n",
       "\n",
       "Columns 10 to 19 \n",
       "-0.0447  0.4612 -0.2665  0.1187  0.4125 -0.8900 -0.0408  0.5004 -1.1695 -0.2581\n",
       "[torch.FloatTensor of size 1x20]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the the model. Note that since we'll want to reuse it for different inputs, we'll want it to be in a function (or really in a class -- we'll show how to do that later). First, we'll remind ourselves of the dimensions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.2528 -0.2488 -0.2331  ...  -0.3116 -0.3155 -0.3116\n",
      "-0.5442 -0.5795 -0.5402  ...  -0.5951 -0.4853 -0.4108\n",
      "-0.5473 -0.5277 -0.5081  ...  -0.3865 -0.4101 -0.4179\n",
      "          ...             ⋱             ...          \n",
      "-0.2480 -0.2205 -0.2519  ...   0.3206  0.3442  0.2383\n",
      "-0.4819 -0.5015 -0.3839  ...  -0.3721 -0.3957 -0.3564\n",
      "-0.3708 -0.2924 -0.1943  ...   0.4606  0.4213  0.4449\n",
      "[torch.FloatTensor of size 600x1024]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      "-1.1344  0.0258 -2.4930  0.3897  0.4594  0.1391 -0.5726  0.7777 -0.2557 -2.1650\n",
      "\n",
      "Columns 10 to 19 \n",
      "-0.0447  0.4612 -0.2665  0.1187  0.4125 -0.8900 -0.0408  0.5004 -1.1695 -0.2581\n",
      "[torch.FloatTensor of size 1x20]\n",
      "\n",
      "\n",
      "-1.9129e-01  8.4820e-01 -1.3891e+00  ...  -3.4816e-01  5.5355e-01  1.0626e+00\n",
      " 1.2477e+00 -1.1384e+00  1.2539e+00  ...   2.9954e+00 -1.4062e+00  2.7613e+00\n",
      " 6.8777e-01  7.1776e-01  3.8009e-01  ...   8.4149e-01 -1.0920e+00  1.1094e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.1538e+00  2.6159e+00  3.1607e+00  ...   8.8260e-02 -3.8037e-01 -9.4543e-01\n",
      "-3.6796e-01  9.6184e-01  1.3608e+00  ...  -6.4667e-01 -1.0329e+00  1.7793e-01\n",
      "-3.8109e-02 -7.5393e-01  1.8047e+00  ...   4.7727e-01  2.4520e-01  7.7051e-01\n",
      "[torch.FloatTensor of size 1024x20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x.data)\n",
    "print(b0.data)\n",
    "print(W0.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.5065 -1.2022 -0.0388 -1.1708 -2.4451  0.2631\n",
      "[torch.FloatTensor of size 1x6]\n",
      "\n",
      "\n",
      " 0.7867 -0.6407  1.7318 -0.3456 -0.4405  1.0894\n",
      "-1.3830  0.0093  0.8043  0.9598  2.7869  0.0923\n",
      "-0.3521  1.2503  0.1966 -0.3020 -0.5169  0.5635\n",
      " 0.5249  1.7344 -0.9527  0.0373  0.0267 -0.9232\n",
      " 1.6760 -0.6307 -0.7384  1.1678 -0.3742  0.6825\n",
      "-0.8042  0.3415 -0.1001 -1.0073  0.2994  1.2488\n",
      " 0.6572  0.4000 -0.9329 -0.7093  0.2007 -1.4330\n",
      "-0.6654 -1.7852 -0.7719  1.4885 -0.3473 -2.7169\n",
      " 1.5190 -0.2886 -0.4844  2.0773 -0.6403  1.4899\n",
      "-0.2580  0.9112 -0.2918 -0.6118 -1.4890 -0.6615\n",
      " 0.7023  0.1765 -0.3699  0.1038 -1.0866  0.3859\n",
      " 0.2949  0.5264  2.5375  0.3050  0.6688  0.2948\n",
      "-0.9225 -0.4607 -0.0293  1.2828  1.4286 -0.1895\n",
      " 1.2519 -0.3709  1.5053 -1.1414 -0.4688  0.4657\n",
      "-0.6303  1.0168  1.9302  0.1391 -0.5996  0.9923\n",
      " 0.2467  1.6851 -1.7668  1.1029  0.9165  1.4617\n",
      "-0.4769  0.6515 -0.9146 -0.0384  1.6727  0.7826\n",
      "-0.2553  0.1113  1.4451  1.3871  0.5152 -1.8237\n",
      "-0.5512  1.2502 -1.1458  0.7496  0.0637  0.5849\n",
      "-1.0475  0.2625 -1.1697 -0.6223 -0.5773 -1.5300\n",
      "[torch.FloatTensor of size 20x6]\n",
      "\n",
      "\n",
      "    1     0     0     0     0     0\n",
      "    1     0     0     0     0     0\n",
      "    1     0     0     0     0     0\n",
      "                 ⋮                  \n",
      "    0     0     0     0     0     1\n",
      "    0     0     0     0     0     1\n",
      "    0     0     0     0     0     1\n",
      "[torch.FloatTensor of size 600x6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(b1.data)\n",
    "print(W1.data)\n",
    "print(y.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(x, b0, W0, b1, W1):\n",
    "    h = torch.matmul(x, W0) + b0.repeat(x.data.shape[0], 1)\n",
    "    out = torch.matmul(h, W1) + b1.repeat(h.data.shape[0], 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = model(x, b0, W0, b1, W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logSoftMax = torch.nn.LogSoftmax() # We'll be too lazy to define this one by hand\n",
    "loss = -torch.mean(torch.sum(y * logSoftMax(y_out), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 34.9391\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss 34.93908\n",
      "\n",
      "Iteration 100, Loss 1.29915\n",
      "\n",
      "Iteration 200, Loss 0.71944\n",
      "\n",
      "Iteration 300, Loss 0.62156\n",
      "\n",
      "Iteration 400, Loss 0.53066\n",
      "\n",
      "Iteration 500, Loss 0.46348\n",
      "\n",
      "Iteration 600, Loss 0.41200\n",
      "\n",
      "Iteration 700, Loss 0.36804\n",
      "\n",
      "Iteration 800, Loss 0.32848\n",
      "\n",
      "Iteration 900, Loss 0.29268\n",
      "\n",
      "Iteration 1000, Loss 0.26009\n",
      "\n",
      "Iteration 1100, Loss 0.23029\n",
      "\n",
      "Iteration 1200, Loss 0.20298\n",
      "\n",
      "Iteration 1300, Loss 0.17791\n",
      "\n",
      "Iteration 1400, Loss 0.15487\n",
      "\n",
      "Iteration 1500, Loss 0.13369\n",
      "\n",
      "Iteration 1600, Loss 0.11438\n",
      "\n",
      "Iteration 1700, Loss 0.09720\n",
      "\n",
      "Iteration 1800, Loss 0.08260\n",
      "\n",
      "Iteration 1900, Loss 0.07080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-1\n",
    "\n",
    "for t in range(2000):\n",
    "    y_out = model(x, b0, W0, b1, W1)\n",
    "    loss = -torch.mean(torch.sum(y * logSoftMax(y_out), 1))\n",
    "    loss.backward()\n",
    "    b0.data -= learning_rate * b0.grad.data\n",
    "    W0.data -= learning_rate * W0.grad.data\n",
    "    \n",
    "    b1.data -= learning_rate * b1.grad.data\n",
    "    W1.data -= learning_rate * W1.grad.data\n",
    "    \n",
    "    \n",
    "    b0.grad.data.zero_()\n",
    "    W0.grad.data.zero_()\n",
    "    b1.grad.data.zero_()\n",
    "    W1.grad.data.zero_()\n",
    "    \n",
    "    if t%100 == 0:\n",
    "        print(\"Iteration %d, Loss %.5f\\n\"%(t,loss.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_all_var = Variable(torch.from_numpy(test_x), requires_grad=False).type(dtype_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_out = model(x_test_all_var, b0, W0, b1, W1).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 4, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 4, 2, 3, 5, 3, 5, 3, 0,\n",
       "       2, 3, 3, 2, 5, 4, 3, 5, 3, 5, 5, 2, 4, 4, 2, 4, 4, 4, 4, 3, 1, 4, 4,\n",
       "       0, 0, 4, 5, 4, 5, 4, 2, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 2, 5,\n",
       "       5, 2, 2, 5, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test_out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70833333333333337"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.argmax(y_test_out, 1) == np.argmax(test_y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
