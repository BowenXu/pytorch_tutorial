{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Networks\n",
    "\n",
    "To showcase the power of PyTorch's dynamic graphs, we will implement a fully-connected ReLU network <br>\n",
    "that on each forward pass randomly chooses a number between 0 and 3 and has that many hidden layers, <br>\n",
    "reusing the same weights multiple times to compute the innermost hidden layers.\n",
    "\n",
    "Orginal content by Justin Johnson\n",
    "https://github.com/jcjohnson/pytorch-examples/blob/master/nn/dynamic_net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DynamicNet(torch.nn.Module):\n",
    "  def __init__(self, D_in, H, D_out):\n",
    "    \"\"\"\n",
    "    In the constructor we construct three nn.Linear instances that we will use\n",
    "    in the forward pass.\n",
    "    \"\"\"\n",
    "    super(DynamicNet, self).__init__()\n",
    "    self.input_linear = torch.nn.Linear(D_in, H)\n",
    "    self.middle_linear = torch.nn.Linear(H, H)\n",
    "    self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "    and reuse the middle_linear Module that many times to compute hidden layer\n",
    "    representations.\n",
    "    Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "    Python control-flow operators like loops or conditional statements when\n",
    "    defining the forward pass of the model.\n",
    "    Here we also see that it is perfectly safe to reuse the same Module many\n",
    "    times when defining a computational graph. This is a big improvement from Lua\n",
    "    Torch, where each Module could be used only once.\n",
    "    \"\"\"\n",
    "    \n",
    "    h_relu = self.input_linear(x).clamp(min=0)\n",
    "    num_hidden_layers = random.randint(0, 3)\n",
    "    for _ in range(num_hidden_layers):\n",
    "      h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "    y_pred = self.output_linear(h_relu)\n",
    "    \n",
    "    return y_pred, num_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 100, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 200, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 300, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 400, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 500, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 600, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 700, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 800, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 900, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 1000, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 1100, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 1200, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 1300, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 1400, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 1500, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 1600, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 1700, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 1800, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 1900, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 2000, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 2100, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 2200, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 2300, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 2400, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 2500, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 2600, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 2700, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 2800, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 2900, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 3000, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 3100, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 3200, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 3300, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 3400, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 3500, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 3600, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 3700, Loss 595.73450, Number Of Hidden Layers 2\n",
      "\n",
      "Iteration 3800, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 3900, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 4000, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 4100, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 4200, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 4300, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 4400, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n",
      "Iteration 4500, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 4600, Loss 600.79181, Number Of Hidden Layers 1\n",
      "\n",
      "Iteration 4700, Loss 595.12225, Number Of Hidden Layers 3\n",
      "\n",
      "Iteration 4800, Loss 626.55396, Number Of Hidden Layers 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables\n",
    "x = Variable(torch.randn(N, D_in))\n",
    "y = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(5000):\n",
    "  # Forward pass: Compute predicted y by passing x to the model\n",
    "  y_pred, num_hidden_layers = model(x)\n",
    "\n",
    "  # Compute and print loss\n",
    "  loss = criterion(y_pred, y)\n",
    "  if t % 100 == 0:\n",
    "      print(\"Iteration %d, Loss %.5f, Number Of Hidden Layers %d\\n\" %(t, loss.data[0], num_hidden_layers))\n",
    "\n",
    "  # Zero gradients, perform a backward pass, and update the weights.\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
